{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4301b50",
   "metadata": {},
   "source": [
    "# ETL (Extract Transform Load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dc7ba1",
   "metadata": {},
   "source": [
    "#### This notebook contains method to extract, transform and load the sanctions datasets. This code will be written in \".py\" and loaded to a server later to enable the code to be run automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa1f73",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c1c98",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4777470d",
   "metadata": {},
   "source": [
    "#### For the extracation the following will be implemented:\n",
    " - Check if the file needed is present\n",
    "   - If not present, download the file and append the file's date to the file (we can retrieve the date downloaded by querying the modified time as the file will only be modified once)\n",
    " - If it is present, check if the files are older than 7 days. If they are check for new files and download if available\n",
    " \n",
    " \n",
    "#### The following are the naming structure that will be adopted for the files:\n",
    " - regime.json -- will be called --> regimes_{date}.json\n",
    " - 20230607-FULL-1_1.csv -- will be called --> person_two_{date}.csv\n",
    " - 20230607-FULL-1_0.csv -- will be called --> person_one_{date}.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c991cb45",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade5918",
   "metadata": {},
   "source": [
    "# Extraction Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6424d5e",
   "metadata": {},
   "source": [
    "#### The code below can be used to extract the data required (Currently, it will only extract if the current data is older than 7 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f9f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from datetime import date, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Peoples(Enum):\n",
    "    regime = 'regime'\n",
    "    person_one = 'person_one'\n",
    "    person_two = 'person_two'\n",
    "\n",
    "\n",
    "class Extract():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.regimes_url = 'https://www.sanctionsmap.eu/api/v1/regime'\n",
    "        self.persons_url = 'https://webgate.ec.europa.eu/fsd/fsf/public/rss'\n",
    "        \n",
    "    \n",
    "    \n",
    "    def latest_file(self, files_list):\n",
    "        latest_file = files_list\n",
    "        if isinstance(files_list, list):\n",
    "            # create lists containing only modified time and file name\n",
    "            files_list = [[os.path.getmtime(file), file] for file in latest_file]\n",
    "            latest_file = max(files_list)[1]\n",
    "        return latest_file\n",
    "\n",
    "    \n",
    "    def get_file_date(self, file):\n",
    "        file_date = os.path.getmtime(file)\n",
    "        file_date = date.fromtimestamp(file_date)\n",
    "        return file_date\n",
    "        \n",
    "    \n",
    "    def is_file_current(self, file):\n",
    "        file_date = self.get_file_date(file)\n",
    "        check_date = date.today() + relativedelta(days=-7)\n",
    "        if file_date  < check_date:\n",
    "            return False\n",
    "        return True\n",
    "            \n",
    "        \n",
    "    def check_files(self, files_list):\n",
    "        latest_file = files_list\n",
    "        if len(files_list) >= 1:\n",
    "            latest_file = self.latest_file(files_list)\n",
    "            if self.is_file_current(latest_file):\n",
    "                return (False, latest_file)        \n",
    "        # No files available/No current files (prompts download)\n",
    "        return (True, latest_file)\n",
    " \n",
    "\n",
    "    def create_file_names_with_dates(self):\n",
    "        file_names = file_names = {f\"{Peoples.regime.value}\": \"json\", \n",
    "                                   f\"{Peoples.person_one.value}\":\"csv\", \n",
    "                                   f\"{Peoples.person_two.value}\":\"csv\"}\n",
    "        \n",
    "        todays_date_str = date.today().strftime('%Y_%m_%d')\n",
    "        files_todays_date = [f\"{file}_{todays_date_str}.{file_names[file]}\" \n",
    "                             for file in file_names]\n",
    "        return files_todays_date\n",
    "    \n",
    "    \n",
    "    def get_person_urls(self):\n",
    "        resp = requests.get(self.persons_url)\n",
    "        soup = BeautifulSoup(resp.text, 'xml')\n",
    "        tags = soup.find_all('enclosure', attrs = {'type': 'text/plain'})\n",
    "\n",
    "        # take only the first 2 (make adjustments if structure changes in future)\n",
    "        urls = [tag['url'] for tag in tags][:2]\n",
    "        urls.sort()\n",
    "        persons = [Peoples.person_one.value, Peoples.person_two.value]\n",
    "        person_url = list(zip(persons, urls))\n",
    "\n",
    "        pub_date = str(soup.find('pubDate')).strip('</pubDate>').replace(\" GMT\", \"\")\n",
    "        pub_date = datetime.strptime(pub_date, '%a, %d %b %Y %H:%M:%S')\n",
    "        return (pub_date, person_url)\n",
    "                    \n",
    "        \n",
    "    def check_published_date(self, pub_date, file_date):\n",
    "        file_date = \"_\".join(file_date.split('_')[2:]).split(\".\")[0]\n",
    "        file_date = datetime.strptime(file_date, '%Y_%m_%d')\n",
    "        # No need for 7 or + days check (previous check was done)\n",
    "        if pub_date > file_date:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "     \n",
    "    def enable_download(self, person_file, pub_date):\n",
    "        if len(person_file) >= 1:\n",
    "                latest_file = self.latest_file(person_file)\n",
    "                if self.check_published_date(pub_date, latest_file):\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "        \n",
    "    def download_file(self, url, dest_file_name):\n",
    "        # return httpmessage or httperror\n",
    "        try:\n",
    "            file_down = urllib.request.urlretrieve(url, dest_file_name)\n",
    "            return (dest_file_name, file_down[1])\n",
    "        except Exception as e:\n",
    "            return (dest_file_name, e)\n",
    "    \n",
    "    \n",
    "    def persons_file(self):\n",
    "        # regimes is only downloaded if other files are out of date (no checking needed)\n",
    "        files_needed = [glob.glob(e) for e in [f'{Peoples.person_one.value}*', \n",
    "                                               f'{Peoples.person_two.value}*']]\n",
    "        person_one = files_needed[0]\n",
    "        person_two = files_needed[1]\n",
    "        return person_one, person_two\n",
    "    \n",
    "        \n",
    "    def main(self):\n",
    "        persons_file = self.persons_file()\n",
    "        person_one = persons_file[0]\n",
    "        person_two = persons_file[1]\n",
    "        \n",
    "        # check if files are latest\n",
    "        p_one_check = self.check_files(person_one)[0]\n",
    "        p_two_check = self.check_files(person_two)[0]\n",
    "        \n",
    "        current_file_names = self.create_file_names_with_dates()\n",
    "        person_one_download = person_two_download = regimes_download = ''\n",
    "        \n",
    "        if any([p_one_check, p_two_check]):\n",
    "            person_urls = self.get_person_urls()\n",
    "            pub_date = person_urls[0]\n",
    "            \n",
    "            if self.enable_download(person_one, pub_date):\n",
    "                person_one_download = self.download_file(person_urls[1][0][1], \n",
    "                                                         current_file_names[1])\n",
    "            \n",
    "            if self.enable_download(person_two, pub_date):\n",
    "                person_two_download = self.download_file(person_urls[1][1][1], \n",
    "                                                         current_file_names[2])\n",
    "                \n",
    "            if ('person_two_download' or 'person_one_download') in locals():\n",
    "                regimes_download = self.download_file(self.regimes_url, \n",
    "                                                      current_file_names[0])\n",
    "                       \n",
    "            \n",
    "        # Use return to object later to identify downloaded items\n",
    "        return regimes_download, person_one_download, person_two_download   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f221ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extract().main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faeb1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
